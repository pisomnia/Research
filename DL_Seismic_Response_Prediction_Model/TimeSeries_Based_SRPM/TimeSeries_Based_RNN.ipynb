{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from math import sqrt\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from random import sample \n",
    "\n",
    "## Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>K1</th>\n",
       "      <th>Q</th>\n",
       "      <th>K2</th>\n",
       "      <th>T</th>\n",
       "      <th>Q/W</th>\n",
       "      <th>Drift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2210000.0</td>\n",
       "      <td>7.148</td>\n",
       "      <td>25600000.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.58684</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.015880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2210000.0</td>\n",
       "      <td>7.148</td>\n",
       "      <td>25600000.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.58684</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2210000.0</td>\n",
       "      <td>7.148</td>\n",
       "      <td>25600000.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.58684</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.020033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2210000.0</td>\n",
       "      <td>7.148</td>\n",
       "      <td>25600000.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.58684</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.005326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2210000.0</td>\n",
       "      <td>7.148</td>\n",
       "      <td>25600000.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.58684</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.004037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight  Height          K1          Q         K2        T    Q/W  \\\n",
       "0  2210000.0   7.148  25600000.0  1090000.0  1700000.0  0.58684  0.493   \n",
       "1  2210000.0   7.148  25600000.0  1090000.0  1700000.0  0.58684  0.493   \n",
       "2  2210000.0   7.148  25600000.0  1090000.0  1700000.0  0.58684  0.493   \n",
       "3  2210000.0   7.148  25600000.0  1090000.0  1700000.0  0.58684  0.493   \n",
       "4  2210000.0   7.148  25600000.0  1090000.0  1700000.0  0.58684  0.493   \n",
       "\n",
       "      Drift  \n",
       "0  0.015880  \n",
       "1  0.004240  \n",
       "2  0.020033  \n",
       "3  0.005326  \n",
       "4  0.004037  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression\n",
    "## 300 records from Northridge with dt=0.005 and T=30\n",
    "NR_data=pd.read_csv('Result_NR_300.csv',header=None)\n",
    "NR_data.columns = ['Weight','Height','K1','Q','K2','T','Q/W','Drift']\n",
    "NR_data.index = range(len(NR_data))\n",
    "NR_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"Dynamic Analysis/GM_Northridge_ReSize_Opensees/\"  #待读取的文件夹\n",
    "path_list=os.listdir(path)\n",
    "path_list.sort(key = lambda x: int(x[:-4]))\n",
    "GM=np.zeros((300,6000,1))\n",
    "#shape: No of GM * No of Frequency Segement * NO of Time Segment \n",
    "for i in range(300):\n",
    "    x=np.loadtxt(os.path.join(path,path_list[i]))\n",
    "    x.shape = (6000,1)\n",
    "    GM[i] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the dataset into the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wangdong90\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13500, 6000, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Num</th>\n",
       "      <td>10800</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Train  Test\n",
       "Num  10800  2700"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wangdong90\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "c:\\users\\wangdong90\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10800, 6000, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X=NR_data.drop(['Weight','Height','K1','Q','K2','Drift'],axis=1)\n",
    "# y=NR_data['Drift']\n",
    "new_data=NR_data.drop(['Weight','Height','K1','Q','K2'],axis=1)\n",
    "new_data.shape\n",
    "idx=new_data.index.values\n",
    "data_GM=GM[[idx%300]]\n",
    "data_GM.shape\n",
    "\n",
    "data_train,data_test,GM_train,GM_test = train_test_split(new_data, data_GM,test_size=0.2,shuffle=True)\n",
    "Summary=pd.DataFrame(np.array([[len(data_train), len(data_test)]]),columns=['Train', 'Test'],index=['Num'])\n",
    "Summary\n",
    "\n",
    "BR_train = data_train.iloc[:,:2].as_matrix()\n",
    "y_train  = data_train.iloc[:, 2].tolist()\n",
    "BR_test  = data_test.iloc[:,:2].as_matrix()\n",
    "y_test   = data_test.iloc[:, 2].tolist()\n",
    "\n",
    "BR_train = np.expand_dims(BR_train, axis=1)\n",
    "BR_test = np.expand_dims(BR_test, axis=1)\n",
    "BR_train = np.repeat(BR_train, 6000,axis=1)\n",
    "BR_test = np.repeat(BR_test, 6000, axis=1)\n",
    "BR_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D,MaxPooling1D,concatenate,Flatten\n",
    "from keras.layers import LSTM, GRU, CuDNNLSTM, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(GM_shape ,BR_shape, num_cnn_layer, num_rnn_layer, num_fc_layer, layer_cnn, layer_rnn, layer_fc, batch_norm, drop_rate):  \n",
    "  # Step 1: CONV layer (≈4 lines)\n",
    "    #model = Conv1D(64, kernel_size=3, strides=2,padding='same')(input_GM)      # CONV1D\n",
    "    #model = BatchNormalization()(model)                         # Batch normalization\n",
    "    #model = Activation('relu')(model)                           # ReLu activation\n",
    "    #model = Dropout(0.8)(model)                                 # dropout (use 0.8)\n",
    "\n",
    "    GM_input= Input(shape=GM_shape)\n",
    "    BR_input = Input(shape=BR_shape)\n",
    "   \n",
    "    cnn_layer = concatenate([GM_input, BR_input], axis=2)\n",
    "    for i in range(num_cnn_layer):\n",
    "        cnn_layer = Conv1D(filters=layer_cnn[i], kernel_size=3, padding='same')(cnn_layer)\n",
    "        if batch_norm:\n",
    "            cnn_layer = BatchNormalization()(cnn_layer)  \n",
    "        cnn_layer = Activation('relu')(cnn_layer)  \n",
    "        cnn_layer = Dropout(rate=drop_rate)(cnn_layer)\n",
    "        cnn_layer = MaxPooling1D(pool_size=2, strides=4)(cnn_layer)\n",
    "        \n",
    "    rnn_layer = cnn_layer    \n",
    "    for i in range(num_rnn_layer):\n",
    "        rnn_layer = LSTM(units=layer_rnn[i], return_sequences=True)(rnn_layer)\n",
    "        if batch_norm:\n",
    "            rnn_layer = BatchNormalization()(rnn_layer)  \n",
    "        rnn_layer = Activation('relu')(rnn_layer)  \n",
    "        rnn_layer = Dropout(rate=drop_rate)(rnn_layer)\n",
    "        \n",
    "    fc = Flatten()(rnn_layer)\n",
    "    for i in range(num_fc_layer):\n",
    "        fc = Dense(layer_fc[i], activation='relu')(fc)\n",
    "    \n",
    "    output = Dense(1)(fc)\n",
    "    model = Model(inputs=[GM_input, BR_input], outputs=[output])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration Setup\n",
    "GM_shape = (6000,1)\n",
    "BR_shape = (6000,2)\n",
    "\n",
    "num_cnn_layer = 3\n",
    "num_rnn_layer = 3\n",
    "num_fc_layer = 4\n",
    "\n",
    "layer_cnn = (16,32,32)\n",
    "layer_rnn = (32, 64, 64)\n",
    "layer_fc = (128,64,32,10)\n",
    "\n",
    "batch_size = 60\n",
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "lr_decay_momentum= 0.0001\n",
    "drop_rate=0.2\n",
    "\n",
    "batch_norm = True\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"mean_absolute_error\"\n",
    "gpu=True\n",
    "working_directory = \"model_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 6000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 6000, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 6000, 3)      0           input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 6000, 16)     160         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6000, 16)     64          conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6000, 16)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 6000, 16)     0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 1500, 16)     0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1500, 32)     1568        max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1500, 32)     128         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1500, 32)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 1500, 32)     0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 375, 32)      0           dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 375, 32)      3104        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 375, 32)      128         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 375, 32)      0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 375, 32)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 94, 32)       0           dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 94, 32)       8320        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 94, 32)       128         lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 94, 32)       0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 94, 32)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 94, 64)       24832       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 94, 64)       256         lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 94, 64)       0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 94, 64)       0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 94, 64)       33024       dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 94, 64)       256         lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 94, 64)       0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 94, 64)       0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 6016)         0           dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          770176      flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 64)           8256        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 32)           2080        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 10)           330         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1)            11          dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 852,821\n",
      "Trainable params: 852,341\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 10800 samples, validate on 2700 samples\n",
      "Epoch 1/200\n",
      " - 94s - loss: 0.0451 - val_loss: 0.0250\n",
      "Epoch 2/200\n",
      " - 88s - loss: 0.0248 - val_loss: 0.0243\n",
      "Epoch 3/200\n",
      " - 88s - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 4/200\n",
      " - 87s - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 5/200\n",
      " - 87s - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 6/200\n",
      " - 89s - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 7/200\n",
      " - 88s - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 8/200\n",
      " - 88s - loss: 0.0234 - val_loss: 0.0236\n",
      "Epoch 9/200\n",
      " - 87s - loss: 0.0232 - val_loss: 0.0224\n",
      "Epoch 10/200\n",
      " - 87s - loss: 0.0228 - val_loss: 0.0213\n",
      "Epoch 11/200\n",
      " - 87s - loss: 0.0222 - val_loss: 0.0213\n",
      "Epoch 12/200\n",
      " - 87s - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 13/200\n",
      " - 95s - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 14/200\n",
      " - 98s - loss: 0.0198 - val_loss: 0.0191\n",
      "Epoch 15/200\n",
      " - 98s - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 16/200\n",
      " - 98s - loss: 0.0181 - val_loss: 0.0166\n",
      "Epoch 17/200\n",
      " - 98s - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 18/200\n",
      " - 98s - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 19/200\n",
      " - 97s - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 20/200\n",
      " - 98s - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 21/200\n",
      " - 98s - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 22/200\n",
      " - 98s - loss: 0.0143 - val_loss: 0.0155\n",
      "Epoch 23/200\n",
      " - 98s - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 24/200\n",
      " - 98s - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 25/200\n",
      " - 99s - loss: 0.0122 - val_loss: 0.0140\n",
      "Epoch 26/200\n",
      " - 100s - loss: 0.0111 - val_loss: 0.0155\n",
      "Epoch 27/200\n",
      " - 99s - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 28/200\n",
      " - 98s - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 29/200\n",
      " - 98s - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 30/200\n",
      " - 98s - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 31/200\n",
      " - 98s - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 32/200\n",
      " - 98s - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 33/200\n",
      " - 99s - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 34/200\n",
      " - 99s - loss: 0.0070 - val_loss: 0.0125\n",
      "Epoch 35/200\n",
      " - 98s - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 36/200\n",
      " - 99s - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 37/200\n",
      " - 99s - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 38/200\n",
      " - 98s - loss: 0.0065 - val_loss: 0.0109\n",
      "Epoch 39/200\n",
      " - 98s - loss: 0.0064 - val_loss: 0.0100\n",
      "Epoch 40/200\n",
      " - 98s - loss: 0.0064 - val_loss: 0.0106\n",
      "Epoch 41/200\n",
      " - 98s - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 42/200\n",
      " - 100s - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 43/200\n",
      " - 98s - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 44/200\n",
      " - 99s - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 45/200\n",
      " - 98s - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 46/200\n",
      " - 79s - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 47/200\n",
      " - 76s - loss: 0.0058 - val_loss: 0.0094\n",
      "Epoch 48/200\n",
      " - 77s - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 49/200\n",
      " - 76s - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 50/200\n",
      " - 77s - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 51/200\n",
      " - 77s - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 52/200\n",
      " - 77s - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 53/200\n",
      " - 76s - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 54/200\n",
      " - 76s - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 55/200\n",
      " - 77s - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 56/200\n",
      " - 76s - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 57/200\n",
      " - 76s - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 58/200\n",
      " - 76s - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 59/200\n",
      " - 77s - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 60/200\n",
      " - 76s - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 61/200\n",
      " - 76s - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 62/200\n",
      " - 76s - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 63/200\n",
      " - 77s - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 64/200\n",
      " - 76s - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 65/200\n",
      " - 77s - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 66/200\n",
      " - 77s - loss: 0.0051 - val_loss: 0.0078\n",
      "Epoch 67/200\n",
      " - 77s - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 68/200\n",
      " - 76s - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 69/200\n",
      " - 76s - loss: 0.0046 - val_loss: 0.0073\n",
      "Epoch 70/200\n",
      " - 79s - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 71/200\n",
      " - 78s - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 72/200\n",
      " - 76s - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 73/200\n",
      " - 76s - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 74/200\n",
      " - 77s - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 75/200\n",
      " - 77s - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 76/200\n",
      " - 77s - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 77/200\n",
      " - 77s - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 78/200\n",
      " - 76s - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 79/200\n",
      " - 77s - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 80/200\n",
      " - 77s - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 81/200\n",
      " - 77s - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 82/200\n",
      " - 76s - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 83/200\n",
      " - 76s - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 84/200\n",
      " - 76s - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 85/200\n",
      " - 76s - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 86/200\n",
      " - 76s - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 87/200\n",
      " - 76s - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 88/200\n",
      " - 77s - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 89/200\n",
      " - 76s - loss: 0.0041 - val_loss: 0.0073\n",
      "Epoch 90/200\n",
      " - 77s - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 91/200\n",
      " - 77s - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 92/200\n",
      " - 77s - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 93/200\n",
      " - 76s - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 94/200\n",
      " - 77s - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 95/200\n",
      " - 80s - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 96/200\n",
      " - 77s - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 97/200\n",
      " - 77s - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 98/200\n",
      " - 76s - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 99/200\n",
      " - 77s - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 100/200\n",
      " - 76s - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 101/200\n",
      " - 76s - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 102/200\n",
      " - 76s - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 103/200\n",
      " - 77s - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 104/200\n",
      " - 76s - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 105/200\n",
      " - 76s - loss: 0.0038 - val_loss: 0.0071\n",
      "Epoch 106/200\n",
      " - 76s - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 107/200\n",
      " - 77s - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 108/200\n",
      " - 76s - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 109/200\n",
      " - 76s - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 110/200\n",
      " - 77s - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 111/200\n",
      " - 77s - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 112/200\n",
      " - 76s - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 113/200\n",
      " - 76s - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 114/200\n",
      " - 77s - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 115/200\n",
      " - 76s - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 116/200\n",
      " - 76s - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 117/200\n",
      " - 76s - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 118/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 119/200\n",
      " - 79s - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 120/200\n",
      " - 77s - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 121/200\n",
      " - 77s - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 122/200\n",
      " - 76s - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 123/200\n",
      " - 77s - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 124/200\n",
      " - 76s - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 125/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 126/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 127/200\n",
      " - 76s - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 128/200\n",
      " - 76s - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 129/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 130/200\n",
      " - 76s - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 131/200\n",
      " - 76s - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 132/200\n",
      " - 76s - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 133/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 134/200\n",
      " - 76s - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 135/200\n",
      " - 77s - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 136/200\n",
      " - 77s - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 137/200\n",
      " - 77s - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 138/200\n",
      " - 77s - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 139/200\n",
      " - 77s - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 140/200\n",
      " - 77s - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 141/200\n",
      " - 76s - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 142/200\n",
      " - 76s - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 143/200\n",
      " - 77s - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 144/200\n",
      " - 79s - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 145/200\n",
      " - 76s - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 146/200\n",
      " - 77s - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 147/200\n",
      " - 77s - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 148/200\n",
      " - 76s - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 149/200\n",
      " - 76s - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 150/200\n",
      " - 77s - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 151/200\n",
      " - 76s - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 152/200\n",
      " - 76s - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 153/200\n",
      " - 76s - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 154/200\n",
      " - 77s - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 155/200\n",
      " - 76s - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 156/200\n",
      " - 76s - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 157/200\n",
      " - 76s - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 158/200\n",
      " - 77s - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 159/200\n",
      " - 77s - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 160/200\n",
      " - 77s - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 161/200\n",
      " - 77s - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 162/200\n",
      " - 76s - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 163/200\n",
      " - 77s - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 164/200\n",
      " - 95s - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 165/200\n",
      " - 92s - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 166/200\n",
      " - 80s - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 167/200\n",
      " - 90s - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 168/200\n",
      " - 96s - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 169/200\n",
      " - 95s - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 170/200\n",
      " - 95s - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      " - 95s - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 172/200\n",
      " - 95s - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 173/200\n",
      " - 91s - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 174/200\n",
      " - 88s - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 175/200\n",
      " - 88s - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 176/200\n",
      " - 88s - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 177/200\n",
      " - 88s - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 178/200\n",
      " - 88s - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 179/200\n",
      " - 88s - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 180/200\n",
      " - 98s - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 181/200\n",
      " - 98s - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 182/200\n",
      " - 100s - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 183/200\n",
      " - 99s - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 184/200\n",
      " - 99s - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 185/200\n",
      " - 91s - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 186/200\n",
      " - 90s - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 187/200\n",
      " - 92s - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 188/200\n",
      " - 93s - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 189/200\n",
      " - 90s - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 190/200\n",
      " - 83s - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 191/200\n",
      " - 81s - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 192/200\n",
      " - 89s - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 193/200\n",
      " - 96s - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 194/200\n",
      " - 94s - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 195/200\n",
      " - 90s - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 196/200\n",
      " - 90s - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 197/200\n",
      " - 89s - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 198/200\n",
      " - 89s - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 199/200\n",
      " - 91s - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 200/200\n",
      " - 96s - loss: 0.0029 - val_loss: 0.0055\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25da335e240>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25da8605240>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model loss')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25da335e9e8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## use GPU or CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' (CPU)\n",
    "if gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    \n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "model = create_model(GM_shape ,BR_shape, num_cnn_layer, num_rnn_layer, num_fc_layer, layer_cnn, layer_rnn, layer_fc, batch_norm, drop_rate)\n",
    "\n",
    "if optimizer == 'adam':\n",
    "    opt = Adam(lr = learning_rate, decay = lr_decay_momentum)\n",
    "elif optimizer == 'sgd':\n",
    "    opt = SGD(lr = learning_rate, decay = lr_decay_momentum)\n",
    "model.compile(loss = loss_function, optimizer=opt)\n",
    "\n",
    "filepath = \"rnn_model_2_{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(os.path.join(working_directory, filepath), monitor='val_loss', verbose=0, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "history = model.fit([GM_train, BR_train], y_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = num_epochs,\n",
    "              verbose=2,\n",
    "              validation_data=([GM_test, BR_test], y_test),\n",
    "              callbacks=[checkpoint],\n",
    "              shuffle=True)\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model_name,y_val,y_val_pred):\n",
    "    print(\"The calculated RMSE for \"+model_name+\" is:%0.8f\" % (sqrt(mean_squared_error(y_val, y_val_pred))))\n",
    "    ARD = np.absolute(y_val_pred-y_val)/(y_val)\n",
    "    MARD=np.median(np.absolute(y_val_pred-y_val)/(y_val))\n",
    "    print(\"The median absolute relative deviation is %.4f \"% (MARD))\n",
    "    r2 = r2_score(y_val, y_val_pred)\n",
    "    print(\"The R squared  is %.4f \"% (r2))\n",
    "    return ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = os.listdir(working_directory)\n",
    "model_file = os.path.join(working_directory, ckpt[-1])\n",
    "print(\"Best Model File: %s\" % model_file)\n",
    "best_model = load_model(model_file)\n",
    "\n",
    "y_nn_test = best_model.predict([GM_test, BR_test])\n",
    "y_nn_test = y_nn_test.flatten()\n",
    "model_name = 'RNN Based Seismic Response Prediction Model'\n",
    "ARD = score(model_name, y_test, y_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
